predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
variables <- names(data_train)
variables <- variables[variables != "ViolentCrimesPerPop"]
formula <- paste("ViolentCrimesPerPop ~", paste(variables, collapse = " + "))
model <- gam(as.formula(formula), data = data_train, df = 10)
print(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
variables <- names(data_train)
variables <- variables[variables != "ViolentCrimesPerPop"]
formula <- paste("ViolentCrimesPerPop ~", paste(variables, collapse = " + "))
model <- gam(as.formula(formula), data = data_train, df = 5)
print(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
split <- createDataPartition(y = data_mice2$ViolentCrimesPerPop, p = 0.7, list = FALSE)
data_mice2 <- data_without_not_predictive
init = mice(data_mice2, maxit=0)
meth = init$method
predM = init$predictorMatrix
#meth[] = "norm"
set.seed(103)
imputed = mice(data_mice2, method=meth, predictorMatrix=predM, m=5)
data_mice2 <- complete(imputed)
sapply(data_mice2, function(x) sum(is.na(x)))
split <- createDataPartition(y = data_mice2$ViolentCrimesPerPop, p = 0.7, list = FALSE)
data_train <- data_mice2[split, ]
data_test <- data_mice2[-split, ]
model <- lm(ViolentCrimesPerPop ~ ., data = data_train)
summary(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
model <- randomForest(ViolentCrimesPerPop ~ ., data = data_train)
model <- nnet(ViolentCrimesPerPop ~ ., data = data_train, size = 6, decay = 0.1)
summary(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
variables <- names(data_train)
variables <- variables[variables != "ViolentCrimesPerPop"]
formula <- paste("ViolentCrimesPerPop ~", paste(variables, collapse = " + "))
model <- gam(as.formula(formula), data = data_train, df = 5)
print(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
split <- createDataPartition(y = data_mice$ViolentCrimesPerPop, p = 0.7, list = FALSE)
data_train <- data_mice[split, ]
data_test <- data_mice[-split, ]
model <- lm(ViolentCrimesPerPop ~ ., data = data_train)
summary(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
model <- lm(ViolentCrimesPerPop ~ ., data = data_train)
summary(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
split <- createDataPartition(y = data_mice$ViolentCrimesPerPop, p = 0.7, list = FALSE)
data_train <- data_mice[split, ]
data_test <- data_mice[-split, ]
model <- lm(ViolentCrimesPerPop ~ ., data = data_train)
summary(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
model <- randomForest(ViolentCrimesPerPop ~ ., data = data_train)
data_mice <- data_without_not_predictive
init = mice(data_mice, maxit=0)
meth = init$method
predM = init$predictorMatrix
meth[] = "norm"
set.seed(103)
imputed = mice(data_mice, method=meth, predictorMatrix=predM, m=5)
data_mice <- complete(imputed)
sapply(data_mice, function(x) sum(is.na(x)))
split <- createDataPartition(y = data_mice$ViolentCrimesPerPop, p = 0.7, list = FALSE)
data_train <- data_mice[split, ]
data_test <- data_mice[-split, ]
model <- lm(ViolentCrimesPerPop ~ ., data = data_train)
summary(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
model <- randomForest(ViolentCrimesPerPop ~ ., data = data_train)
summary(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
model <- nnet(ViolentCrimesPerPop ~ ., data = data_train, size = 6, decay = 0.1)
summary(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
variables <- names(data_train)
variables <- variables[variables != "ViolentCrimesPerPop"]
formula <- paste("ViolentCrimesPerPop ~", paste(variables, collapse = " + "))
model <- gam(as.formula(formula), data = data_train, df = 5)
print(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
variables <- names(data_train)
variables <- variables[variables != "ViolentCrimesPerPop"]
formula <- paste("ViolentCrimesPerPop ~", paste(variables, collapse = " + "))
model <- gam(as.formula(formula), data = data_train, df = 8)
print(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
variables <- names(data_train)
variables <- variables[variables != "ViolentCrimesPerPop"]
formula <- paste("ViolentCrimesPerPop ~", paste(variables, collapse = " + "))
model <- gam(as.formula(formula), data = data_train, df = 200)
print(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
library(e1071)
library(MASS)
myplot <- function(XX, yy) {
cv <- ShuffleSplit(n_splits = 10, test_size = 0.3, random_state = seed)
results <- list()
names <- list()
for (name, model in models) {
?ShuffleSplit
# Séparer les variables prédictives et la variable cible
X <- data_mean[, -y]
y <- data_mean$ViolentCrimesPerPop
y <- data_mean[, -ViolentCrimesPerPop]
y <- data_mean[, -data_mean$ViolentCrimesPerPop]
y <- data_mean[, -data_mean$ViolentCrimesPerPop]
y <- data_mean[, data_mean$ViolentCrimesPerPop]
View(y)
X <- data_mean[, -which(colnames(data_mean) == "ViolentCrimesPerPop")]
y <- data_mean[, which(colnames(data_mean) == "ViolentCrimesPerPop")]
# Définir les modèles à évaluer
models <- list(
lm = lm(y ~ ., data = X),
glm = glm(y ~ ., data = X, family = "gaussian"),
rf = randomForest(y ~ ., data = X),
svm = svm(y ~ ., data = X, type = "eps-regression"),
nnet = nnet(y ~ ., data = X, size = 5, decay = 1e-4)
)
# Définir les paramètres de la cross-validation
cv <- trainControl(method = "cv", number = 10, returnResamp = "all", classProbs = TRUE, summaryFunction = twoClassSummary, verboseIter = TRUE)
# Effectuer la cross-validation et stocker les résultats dans res
res <- lapply(models, function(x) caret::train(x, data = X, trControl = cv, metric = "R2"))
X <- data_mean#[, -which(colnames(data_mean) == "ViolentCrimesPerPop")]
y <- data_mean[, which(colnames(data_mean) == "ViolentCrimesPerPop")]
models <- list(
lm = lm(y ~ ., data = X),
glm = glm(y ~ ., data = X, family = "gaussian"),
rf = randomForest(y ~ ., data = X),
svm = svm(y ~ ., data = X, type = "eps-regression"),
nnet = nnet(y ~ ., data = X, size = 5, decay = 1e-4)
)
# Définir les paramètres de la cross-validation
cv <- trainControl(method = "cv", number = 10, returnResamp = "all", classProbs = TRUE, summaryFunction = twoClassSummary, verboseIter = TRUE)
# Effectuer la cross-validation et stocker les résultats dans res
res <- lapply(models, function(x) caret::train(x, data = X, trControl = cv, metric = "R2"))
# Définir les modèles à évaluer
models <- list(
lm = lm(y ~ ., data = X),
glm = glm(y ~ ., data = X, family = "gaussian"),
rf = randomForest(y ~ ., data = X),
svm = svm(y ~ ., data = X, type = "eps-regression"),
nnet = nnet(y ~ ., data = X, size = 5, decay = 0.1)
)
# Définir les paramètres de la cross-validation
cv <- trainControl(method = "cv", number = 10, returnResamp = "all", classProbs = TRUE, summaryFunction = twoClassSummary, verboseIter = TRUE)
# Effectuer la cross-validation et stocker les résultats dans res
res <- lapply(models, function(x) caret::train(x, data = X, trControl = cv, metric = "R2"))
# Séparer les variables prédictives et la variable cible
X <- data_mean#[, -which(colnames(data_mean) == "ViolentCrimesPerPop")]
y <- data_mean[, which(colnames(data_mean) == "ViolentCrimesPerPop")]
# Définir les modèles à évaluer
models <- list(
lm = lm(y ~ ., data = X),
glm = glm(y ~ ., data = X, family = "gaussian"),
rf = randomForest(y ~ ., data = X),
svm = svm(y ~ ., data = X, type = "eps-regression"),
#nnet = nnet(y ~ ., data = X, size = 5, decay = 0.1)
)
# Définir les modèles à évaluer
models <- list(
lm = lm(y ~ ., data = X),
glm = glm(y ~ ., data = X, family = "gaussian"),
rf = randomForest(y ~ ., data = X),
svm = svm(y ~ ., data = X, type = "eps-regression")
#nnet = nnet(y ~ ., data = X, size = 5, decay = 0.1)
)
# Définir les paramètres de la cross-validation
cv <- trainControl(method = "cv", number = 10, returnResamp = "all", classProbs = TRUE, summaryFunction = twoClassSummary, verboseIter = TRUE)
# Effectuer la cross-validation et stocker les résultats dans res
res <- lapply(models, function(x) caret::train(x, data = X, trControl = cv, metric = "R2"))
models <- list(
"Random Forest" = randomForest(formula = target ~ ., data = data_train),
"Régression Ridge" = glmnet(as.matrix(data_train[, -1]), data_train[, 1], alpha = 0, lambda = 0.1),
"Régression Lasso" = glmnet(as.matrix(data_train[, -1]), data_train[, 1], alpha = 1, lambda = 0.1)
)
models <- list(
"Random Forest" = randomForest(formula = ViolentCrimesPerPop ~ ., data = data_train),
"Régression Ridge" = glmnet(as.matrix(data_train[, -1]), data_train[, 1], alpha = 0, lambda = 0.1),
"Régression Lasso" = glmnet(as.matrix(data_train[, -1]), data_train[, 1], alpha = 1, lambda = 0.1)
)
library(glmnet)
models <- list(
"Random Forest" = randomForest(formula = ViolentCrimesPerPop ~ ., data = data_train),
"Régression Ridge" = glmnet(as.matrix(data_train[, -1]), data_train[, 1], alpha = 0, lambda = 0.1),
"Régression Lasso" = glmnet(as.matrix(data_train[, -1]), data_train[, 1], alpha = 1, lambda = 0.1)
)
results <- resamples(models)
summary(results)
models <- list(
"Random Forest" = randomForest(formula = ViolentCrimesPerPop ~ ., data = data_train),
"Régression Ridge" = glmnet(as.matrix(data_train[, -1]), data_train[, 1], alpha = 0, lambda = 0.1),
"Régression Lasso" = glmnet(as.matrix(data_train[, -1]), data_train[, 1], alpha = 1, lambda = 0.1)
)
results <- resamples(models)
glmnet(as.matrix(data_train[, -1]), data_train[, 1], alpha = 0, lambda = 0.1)
glmnet(as.matrix(data_train[, -1]), data_train[, 1], alpha = 1, lambda = 0.1)
randomForest(formula = ViolentCrimesPerPop ~ ., data = data_train)
?resamples
View(results)
results <- resamples(models)
models <- list(
#"Random Forest" = randomForest(formula = ViolentCrimesPerPop ~ ., data = data_train),
"Régression Ridge" = glmnet(as.matrix(data_train[, -1]), data_train[, 1], alpha = 0, lambda = 0.1),
"Régression Lasso" = glmnet(as.matrix(data_train[, -1]), data_train[, 1], alpha = 1, lambda = 0.1)
)
results <- resamples(models)
models <- list(
"Random Forest" = randomForest(formula = ViolentCrimesPerPop ~ ., data = data_train),
#"Régression Ridge" = glmnet(as.matrix(data_train[, -1]), data_train[, 1], alpha = 0, lambda = 0.1),
"Régression Lasso" = glmnet(as.matrix(data_train[, -1]), data_train[, 1], alpha = 1, lambda = 0.1)
)
results <- resamples(models)
models <- list(
"Random Forest" = randomForest(formula = ViolentCrimesPerPop ~ ., data = data_train),
"Régression Ridge" = glmnet(as.matrix(data_train[, -1]), data_train[, 1], alpha = 0, lambda = 0.1)
#"Régression Lasso" = glmnet(as.matrix(data_train[, -1]), data_train[, 1], alpha = 1, lambda = 0.1)
)
results <- resamples(models)
models <- list(
"Random Forest" = randomForest(formula = ViolentCrimesPerPop ~ ., data = data_train)
#"Régression Ridge" = glmnet(as.matrix(data_train[, -1]), data_train[, 1], alpha = 0, lambda = 0.1)
#"Régression Lasso" = glmnet(as.matrix(data_train[, -1]), data_train[, 1], alpha = 1, lambda = 0.1)
)
results <- resamples(models)
models <- list(
"Random Forest" = randomForest(formula = ViolentCrimesPerPop ~ ., data = data_train),
lm = lm(ViolentCrimesPerPop ~ ., data = data_train)
#"Régression Ridge" = glmnet(as.matrix(data_train[, -1]), data_train[, 1], alpha = 0, lambda = 0.1)
#"Régression Lasso" = glmnet(as.matrix(data_train[, -1]), data_train[, 1], alpha = 1, lambda = 0.1)
)
results <- resamples(models)
models <- list(lm = lm(y ~ X),
glm = glm(y ~ X, family = "gaussian"),
rf = randomForest(y ~ X, ntree = 100))
models <- list(lm = lm(y ~ X),
glm = glm(y ~ X, family = "gaussian"),
rf = randomForest(y ~ X, ntree = 100))
library(visdat)
library(ggplot2)
library(randomForest)
library(missForest)
library(mice)
library(caret)
library(mclust)
library(nnet)
library(mgcv)
library(e1071)
library(MASS)
library(glmnet)
library(leaps)
library(rpart)
set.seed(123)
data <- read.csv("communities_train.csv")
setwd("~/GI02/SY19/projet2/sy19-projet2")
data <- read.csv("communities_train.csv")
tab_mse <- table(x = "modele", y = "mse")
# Jeu de données sans les variables non prédictives (utilisé pour la suite)
data_without_not_predictive <- data[, -(1:5)]
model <- train(y ~ ., data = data, method = "rf", trControl = trainControl(method = "cv", number = 10))
model <- train(y ~ ., data = data, method = "rf", trControl = trainControl(method = "cv", number = 10))
model <- train(y ~ ., data = data_train, method = "rf", trControl = trainControl(method = "cv", number = 10))
model <- train(ViolentCrimesPerPop ~ ., data = data_train, method = "rf", trControl = trainControl(method = "cv", number = 10))
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
liste_mse <- c(liste_mse, list(RandomForestCV = mse))
liste_mse <- list()
liste_mse <- c(liste_mse, list(RandomForestCV = mse))
model <- lm(ViolentCrimesPerPop ~ ., data = data_train)
summary(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
liste_mse <- c(liste_mse, list(RegLinéaire = mse))
tab_mse <- rbind(modele = "RegLinéaire", mse = mse)
model <- lm(ViolentCrimesPerPop ~ ., data = data_train)
summary(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
liste_mse <- c(liste_mse, list(RegLinéaire = mse))
tab_mse <- rbind(modele = "RegLinéaire", mse = mse)
model <- randomForest(ViolentCrimesPerPop ~ ., data = data_train)
summary(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
liste_mse <- c(liste_mse, list(RandomForest = mse))
tab_mse <- rbind(modele = "RandomForest", mse = mse)
split <- createDataPartition(y = data_complete2$ViolentCrimesPerPop, p = 0.9, list = FALSE)
data_train <- data_complete2[split, ]
data_test <- data_complete2[-split, ]
model <- lm(ViolentCrimesPerPop ~ ., data = data_train)
summary(model)
predictions <- predict(model, newdata = data_test)
data <- read.csv("communities_train.csv")
tab_mse <- table(x = "modele", y = "mse")
# Jeu de données sans les variables non prédictives (utilisé pour la suite)
data_without_not_predictive <- data[, -(1:5)]
# Jeu de données sans les observations incomplètes
data_complete <- data_without_not_predictive[complete.cases(data_without_not_predictive), ]
# Jeu de données sans les variables comprenant des observations incomplètes
data_complete2 <- data_without_not_predictive[, colSums(is.na(data_without_not_predictive)) == 0]
split <- createDataPartition(y = data_complete2$ViolentCrimesPerPop, p = 0.9, list = FALSE)
data_train <- data_complete2[split, ]
data_test <- data_complete2[-split, ]
X_train <- subset(data_train, select = -ViolentCrimesPerPop)
y_train <- data_train$ViolentCrimesPerPop
X_test <- subset(data_test, select = -ViolentCrimesPerPop)
y_test <- data_test$ViolentCrimesPerPop
cv <- trainControl(method = "cv", number = 10)
metric <- "MSE"
model <- lm(ViolentCrimesPerPop ~ ., data = data_train)
summary(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
liste_mse <- c(liste_mse, list(RegLinéaire = mse))
tab_mse <- rbind(modele = "RegLinéaire", mse = mse)
data_train <- data_complete2[split, ]
model <- lm(ViolentCrimesPerPop ~ ., data = data_train)
summary(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
liste_mse <- c(liste_mse, list(RegLinéaire = mse))
tab_mse <- rbind(modele = "RegLinéaire", mse = mse)
model <- lm(ViolentCrimesPerPop ~ ., data = data_train)
summary(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
liste_mse <- c(liste_mse, list(RegLinéaire = mse))
tab_mse <- rbind(modele = "RegLinéaire", mse = mse)
model <- lm(ViolentCrimesPerPop ~ ., data = data_train)
summary(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
liste_mse <- c(liste_mse, list(RegLinéaire = mse))
tab_mse <- rbind(modele = "RegLinéaire", mse = mse)
model <- lm(ViolentCrimesPerPop ~ ., data = data_train)
summary(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
liste_mse <- c(liste_mse, list(RegLinéaire = mse))
tab_mse <- rbind(modele = "RegLinéaire", mse = mse)
model <- lm(ViolentCrimesPerPop ~ ., data = data_train)
summary(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
liste_mse <- c(liste_mse, list(RegLinéaire = mse))
tab_mse <- rbind(modele = "RegLinéaire", mse = mse)
model <- randomForest(ViolentCrimesPerPop ~ ., data = data_train)
summary(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
liste_mse <- c(liste_mse, list(RandomForest = mse))
tab_mse <- rbind(modele = "RandomForest", mse = mse)
model <- nnet(ViolentCrimesPerPop ~ ., data = data_train, size = 6, decay = 0.1)
summary(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
liste_mse <- c(liste_mse, list(NeuralNetwork = mse))
variables <- names(data_train)
variables <- variables[variables != "ViolentCrimesPerPop"]
formula <- paste("ViolentCrimesPerPop ~", paste(variables, collapse = " + "))
model <- gam(as.formula(formula), data = data_train)
print(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
liste_mse <- c(liste_mse, list(GAM = mse))
model <- glmnet(x = X_train, y = y_train, alpha = 1)
predictions <- predict(model, newx = as.matrix(X_test))
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
liste_mse <- c(liste_mse, list(Lasso1 = mse))
cv.out <- cv.glmnet(as.matrix(X_train), y_train, alpha=1, standardize=TRUE)
model <- glmnet(X_train, y_train, lambda=cv.out$lambda.min, alpha=1, standardize=TRUE)
predictions <- predict(model, s=cv.out$lambda.min, newx = as.matrix(X_test))
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
liste_mse <- c(liste_mse, list(Lasso2 = mse))
model <- glmnet(as.matrix(X_train), y_train, alpha = 0, lambda = 0.1)
predictions <- predict(model, newx = as.matrix(X_test))
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
liste_mse <- c(liste_mse, list(Ridge1 = mse))
cv.out <- cv.glmnet(as.matrix(X_train), y_train, alpha=0, standardize=TRUE)
model <- glmnet(X_train, y_train, lambda=cv.out$lambda.min, alpha=0, standardize=TRUE)
predictions <- predict(model, s=cv.out$lambda.min, newx = as.matrix(X_test))
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
liste_mse <- c(liste_mse, list(Ridge2 = mse))
model <- glmnet(X_train, y_train, alpha = 0, nlambda = 100, lambda.min.ratio = 0.0001, standardize = TRUE, intercept = TRUE, score.response = "bic")
predictions <- predict(model, newx = as.matrix(X_test))
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
liste_mse <- c(liste_mse, list(RidgeBIC = mse))
model <- glmnet(X_train, y_train, alpha = 1, standardize = TRUE, intercept = TRUE, score.response = "bic")
predictions <- predict(model, newx = as.matrix(X_test))
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
liste_mse <- c(liste_mse, list(LassoBIC = mse))
model <- rpart(ViolentCrimesPerPop ~ ., data = data_train, control = rpart.control(xval = 10, minbucket = 10, cp = 0))
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
#plotcp(model)
#printcp(model)
liste_mse <- c(liste_mse, list(RegTree = mse))
i.min <- which.min(model$cptable[,4])
cp.opt <- model$cptable[i.min,1]
pruned_tree <- prune(model, cp=cp.opt)
predictions <- predict(pruned_tree, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
liste_mse <- c(liste_mse, list(PrunedTree = mse))
model <- regsubsets(ViolentCrimesPerPop ~.,data=data_train, method='forward', nvmax=30)
res.forward <- summary(model)
best <- which.min(res.forward$bic)
ntst <- nrow(as.matrix(X_test))
X <- cbind(rep(1,ntst),as.matrix(X_test))
ypred<-X[,res.forward$which[best,]]%*%coef(model,best)
mse <-mean((ypred-data_test$ViolentCrimesPerPop)^2)
liste_mse <- c(liste_mse, list(SubSelVar = mse))
keys <- names(liste_mse)
values <- unname(liste_mse)
plot(keys, values, type="b", xlab="Clés", ylab="Valeurs")
values <- unname(liste_mse)
View(values)
keys <- names(liste_mse)
values <- unname(liste_mse)
plot(keys, values, type="b", xlab="Clés", ylab="Valeurs")
View(liste_mse)
View(liste_mse)
names(liste_mse)
list(names(liste-mse))
list(names(liste_mse))
plot(values, values, type="b", xlab="Clés", ylab="Valeurs")
plot(t(keys), values, type="b", xlab="Clés", ylab="Valeurs")
t(keys)
unlist(liste_mse)
plot(unlist(liste_mse))
View(liste_mse)
unlist(liste_mse)
liste_mse <- list()
model <- lm(ViolentCrimesPerPop ~ ., data = data_train)
summary(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
liste_mse <- c(liste_mse, list(RegLinéaire = mse))
tab_mse <- rbind(modele = "RegLinéaire", mse = mse)
results <- train(ViolentCrimesPerPop ~ ., data = data_complete2, method = "lm", trControl = cv, metric = metric)
print(results)
View(results)
0.1450734^2
model <- randomForest(ViolentCrimesPerPop ~ ., data = data_train)
summary(model)
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
split <- createDataPartition(y = data_without_not_predictive$ViolentCrimesPerPop, p = 0.9, list = FALSE)
data_train2 <- data_without_not_predictive[split, ]
data_test2 <- data_without_not_predictive[-split, ]
model <- randomForest(ViolentCrimesPerPop ~ ., data = data_train2)
liste_mse <- c(liste_mse, list(RandomForest = mse))
tab_mse <- rbind(modele = "RandomForest", mse = mse)
model <- train(ViolentCrimesPerPop ~ ., data = data_train, method = "rf", trControl = trainControl(method = "cv", number = 10))
predictions <- predict(model, newdata = data_test)
mse <- mean((predictions - data_test$ViolentCrimesPerPop)^2)
print(mse)
liste_mse <- c(liste_mse, list(RandomForestCV = mse))
tab_mse <- rbind(modele = "RandomForestCV", mse = mse)
